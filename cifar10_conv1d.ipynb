{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we present an algorithm that maps 2D data to 1D and show that 1D CNNs comparable with 2D CNNs. In particular, we read image pixels with Hilbert and modified Sierpinski space-filling curves, and then apply one-dimensional convolutional neural networks. \n",
    "\n",
    "We know that space-filling curves preserve a maximum of spatial locality information between elements. We believe that using space-filling curve mapping as a preprocessing tool, preserves enough information of neighbouring pixels to be used by 1D CNNs. We evaluated the classification performance of 1D CNNs on Cifar-10 image dataset. This mapping technique reduces CNN training cost while performs comparably to 2D CNNs.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "\n",
    "from space_filling_curves import rix, hilbert_curve, scan_image_with_hilbert, modified_sierpinski_curve, scan_image_with_sierpinski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIFAR-10 dataset consists of 60000 32x32x3 color images in 10 equal classes. There are 50000 training images and 10000 test images. Each class of images corresponds to a physical object such as airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n",
      "It is a bird!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "num_classes = 10\n",
    "cifar10_classes = {0:'airplane', 1:'automobile', 2:'bird', 3:'cat', 4:'deer', \n",
    "                      5:'dog', 6:'frog', 7:'horse', 8:'ship', 9:'truck'}\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "def draw_cifar_image(i):\n",
    "    img = x_train[i]\n",
    "    label = y_train[i]    \n",
    "    plt.imshow(img)\n",
    "\n",
    "    \n",
    "print(\"It is a \" + str(cifar10_classes[int(y_train[13])]) + \"!\")\n",
    "draw_cifar_image(13)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read the image pixels with Hilbert space-filling curve or modified Sierpinski space-filling curve. The main difference between these two curves is that modified Sierpinski curve is more symmetrical and closed.\n",
    "\n",
    "Here, for example, we read the red matrix of the 4x4x3 image with Hilbert curve in the following order: 35, 19, 22, 13, 4, 0, 8, 3, 7, 1, 3, 10, 53, 16, 25, 6. We read the red matrix of the 4x4x3 image with modified Sierpinski curve in the following order: 35, 19, 22, 25, 6, 53, 16, 10, 3, 1, 7, 8, 0, 4, 3, 13. The code in Python 3 (see space_filling_curves.py) shows how to build the modified Nth order Sierpinski curve and Nth order Hilbert curve.\n",
    "\n",
    "\n",
    "2nd-order Hilbert curve | 2nd-order modified Sierpiński curve\n",
    ":-------------------------:|:-------------------------:\n",
    "<img src=\"images/hilbertRGB.png\" style=\"width:400px;height:300px\"/>  |  <img src=\"images/readwithcurve.png\" style=\"width:400px;height:300px\"/>\n",
    "\n",
    "\n",
    "\n",
    "Although it is possible to use lower order of the curves to read images, it is not recommended for small images. Here we preserve every pixel in image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The order of the curve is 5\n",
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n",
      "(50000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "num_px = x_train.shape[1]\n",
    "N = math.log10(num_px) / math.log10(2)\n",
    "N = int(N) # to cover all pixels\n",
    "print(\"The order of the curve is \" + str(N)) \n",
    "#x,y = modified_sierpinski_curve(N)\n",
    "x,y = hilbert_curve(N)\n",
    "\n",
    "# normalize data\n",
    "X_train_orig = x_train/255.\n",
    "X_test_orig = x_test/255.\n",
    "mtrain = X_train_orig.shape[0]\n",
    "mtest = X_test_orig.shape[0]\n",
    "\n",
    "# convert to one-hot presentation\n",
    "Y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "Y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# print shapes\n",
    "print(X_train_orig.shape)\n",
    "print(X_test_orig.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create arrays of zeros and read pixels with Hilbert curve for Red, Green, and Blue channels. The data therefore transformed from (number of examples, number of pixels, number of pixels, 3) to (number of examples, $2^{2N}$, 3), where $N$ is the order of the curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1024, 3)\n",
      "(10000, 1024, 3)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.zeros([X_train_orig.shape[0], 2**(2*N), X_train_orig.shape[3]])\n",
    "test_data = np.zeros([X_test_orig.shape[0], 2**(2*N), X_test_orig.shape[3]])\n",
    "\n",
    "train_data[:, :, 0] = scan_image_with_hilbert(N, mtrain, X_train_orig[:, :, :, 0], x, y)        \n",
    "test_data[:, :, 0] = scan_image_with_hilbert(N, mtest, X_test_orig[:, :, :, 0], x, y) \n",
    "\n",
    "train_data[:, :, 1] = scan_image_with_hilbert(N, mtrain, X_train_orig[:, :, :, 1], x, y)        \n",
    "test_data[:, :, 1] = scan_image_with_hilbert(N, mtest, X_test_orig[:, :, :, 1], x, y) \n",
    "\n",
    "train_data[:, :, 2] = scan_image_with_hilbert(N, mtrain, X_train_orig[:, :, :, 2], x, y)        \n",
    "test_data[:, :, 2] = scan_image_with_hilbert(N, mtest, X_test_orig[:, :, :, 2], x, y) \n",
    "\n",
    "# new shapes\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the model as a Sequential model in Keras. We define the model as having two blocks of two 1D CNN layers followed by  a pooling layer, then a dropout layer for regularization. After that, the learned features are flattened to a vector and pass through a fully connected layer. Then the output layer used to make predictions. We use batch normalization and ELU activation function elsewhere. Adam optimizer with default learning rate of 0.001 was used. We trained this model for 10 epochs using batches of 32 examples and achieved 88% train accuracy and 70.06% test accuracy. It took 1550 seconds to run. \n",
    "\n",
    "\n",
    "More details about the model hyperparameters are below:\n",
    "\n",
    "In the first block we use\n",
    "- 1D convolutional layers with 32 filters (feature detectors), each of length 4 (kernel size or sliding window). In this initial layer, 32 sliding windows of size 4 will run through the data to learn basic features. This allows us to train 32 different features on the first layer of the network.\n",
    "- The exponential linear unit (ELU) activation function has a nonzero gradient for $z < 0$. It was used to avoid the dying units issue (some neurons die and output 0) when using RELU.\n",
    "- To zero-center and normalize the inputs, we use the batch normalization techique that evaluates mean and standard deviation  of the inputs over the current mini-batch. This technique makes the networks much less sensitive to the weight initialization.\n",
    "- MaxPooling of size 2 and stride 1 was applied by taking the max value of every 2 features. This means that the size of the output matrix of this layer is only a half of the input matrix.\n",
    "- Dropout layer with rate 0.25 was used to ensure that at every trainig step, every input neuron has the probability 0.25 of being temporarily dropped (ignored). This means that the network becomes less sensitive to react to smaller variations in the data, and likely will increase test accuracy.\n",
    "\n",
    "The second block is similar to the first one, except more filters were used and AveragePooling was used instead of MaxPooling. After that we 'flatten' and turn the output into a vector. The first fully connected layer defined as Dense(128) takes the input from the features analysis and applies weights to predict the correct label. The last output layer defined by Dense(num_classes) uses a softmax activation function to give probabilities for the num_classes=10 output classes.\n",
    "\n",
    "\n",
    "We train our model for 10 epochs, meaning that we completely pass through the training dataset 10 times. After evey 32 training examples (batch_size=32) the model's internal parameters were updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0924 15:23:32.739766 140736049849216 deprecation_wrapper.py:119] From /Users/lilybird/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0924 15:23:32.913754 140736049849216 deprecation_wrapper.py:119] From /Users/lilybird/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0924 15:23:32.962187 140736049849216 deprecation_wrapper.py:119] From /Users/lilybird/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0924 15:23:33.166949 140736049849216 deprecation_wrapper.py:119] From /Users/lilybird/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0924 15:23:33.761415 140736049849216 deprecation_wrapper.py:119] From /Users/lilybird/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0924 15:23:33.773067 140736049849216 deprecation.py:506] From /Users/lilybird/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0924 15:23:34.044467 140736049849216 deprecation_wrapper.py:119] From /Users/lilybird/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "W0924 15:23:34.245936 140736049849216 deprecation_wrapper.py:119] From /Users/lilybird/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0924 15:23:34.255944 140736049849216 deprecation_wrapper.py:119] From /Users/lilybird/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0924 15:23:34.412991 140736049849216 deprecation.py:323] From /Users/lilybird/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 430s 9ms/step - loss: 1.4092 - acc: 0.5071 - val_loss: 1.1363 - val_acc: 0.5938\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 408s 8ms/step - loss: 1.0731 - acc: 0.6205 - val_loss: 1.0092 - val_acc: 0.6448\n",
      "Epoch 3/10\n",
      "12288/50000 [======>.......................] - ETA: 5:02 - loss: 0.9066 - acc: 0.6828"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "#сreating 32 different filters, each of them with length 4.\n",
    "model.add(Conv1D(32, 4, input_shape=train_data.shape[1:]))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(32, 4))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Conv1D(64, 4))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(64, 4))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(AveragePooling1D(pool_size=2))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(test_data, Y_test))\n",
    "score = model.evaluate(test_data, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously we read pixels with Hilbert curve. Here we read pixels with modified Sierpinski curve and use the same model as above to train 1D CNNs. After 10 epochs the model achieved 87.52% train accuracy and 70.37% test accuracy in 1546 seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 149s 3ms/step - loss: 1.4345 - acc: 0.4963 - val_loss: 1.1147 - val_acc: 0.6058\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 146s 3ms/step - loss: 1.0788 - acc: 0.6170 - val_loss: 1.0649 - val_acc: 0.6237\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 145s 3ms/step - loss: 0.9200 - acc: 0.6752 - val_loss: 0.9404 - val_acc: 0.6669\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 145s 3ms/step - loss: 0.7986 - acc: 0.7162 - val_loss: 0.9309 - val_acc: 0.6763\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 145s 3ms/step - loss: 0.6879 - acc: 0.7579 - val_loss: 0.8882 - val_acc: 0.6933\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 145s 3ms/step - loss: 0.5922 - acc: 0.7908 - val_loss: 0.9035 - val_acc: 0.7042\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 145s 3ms/step - loss: 0.5149 - acc: 0.8175 - val_loss: 0.9120 - val_acc: 0.7085\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 145s 3ms/step - loss: 0.4494 - acc: 0.8410 - val_loss: 0.9385 - val_acc: 0.7078\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 145s 3ms/step - loss: 0.3994 - acc: 0.8586 - val_loss: 0.9433 - val_acc: 0.7124\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 145s 3ms/step - loss: 0.3584 - acc: 0.8733 - val_loss: 1.0501 - val_acc: 0.6953\n",
      "Test loss: 1.0501061946868897\n",
      "Test accuracy: 0.6953\n",
      "--- 1464.7182071208954 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# read with modified Sierpinski curve\n",
    "\n",
    "x,y = modified_sierpinski_curve(N)\n",
    "\n",
    "train_data = np.zeros([X_train_orig.shape[0], 2**(2*N), X_train_orig.shape[3]])\n",
    "test_data = np.zeros([X_test_orig.shape[0], 2**(2*N), X_test_orig.shape[3]])\n",
    "\n",
    "train_data[:, :, 0] = scan_image_with_hilbert(N, mtrain, X_train_orig[:, :, :, 0], x, y)        \n",
    "test_data[:, :, 0] = scan_image_with_hilbert(N, mtest, X_test_orig[:, :, :, 0], x, y) \n",
    "\n",
    "train_data[:, :, 1] = scan_image_with_hilbert(N, mtrain, X_train_orig[:, :, :, 1], x, y)        \n",
    "test_data[:, :, 1] = scan_image_with_hilbert(N, mtest, X_test_orig[:, :, :, 1], x, y) \n",
    "\n",
    "train_data[:, :, 2] = scan_image_with_hilbert(N, mtrain, X_train_orig[:, :, :, 2], x, y)        \n",
    "test_data[:, :, 2] = scan_image_with_hilbert(N, mtest, X_test_orig[:, :, :, 2], x, y) \n",
    "\n",
    "\n",
    "\n",
    "# train 1D CNNs\n",
    "start_time = time.time()\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(32, 4, input_shape=train_data.shape[1:]))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(32, 4))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Conv1D(32, 4))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(32, 4))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(AveragePooling1D(pool_size=2))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(test_data, Y_test))\n",
    "score = model.evaluate(test_data, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we apply 2D CNNs to the original data. We use similar architecture as for 1D CNNs. The model achieves 77.44% train accuracy and 77.14% test accuracy in 1353 seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 132s 3ms/step - loss: 1.5203 - acc: 0.4630 - val_loss: 1.2408 - val_acc: 0.5543\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 131s 3ms/step - loss: 1.0768 - acc: 0.6208 - val_loss: 0.9628 - val_acc: 0.6628\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 136s 3ms/step - loss: 0.9320 - acc: 0.6736 - val_loss: 0.9056 - val_acc: 0.6804\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 138s 3ms/step - loss: 0.8470 - acc: 0.7036 - val_loss: 0.8327 - val_acc: 0.7054\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 131s 3ms/step - loss: 0.7922 - acc: 0.7236 - val_loss: 0.7220 - val_acc: 0.7450\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 145s 3ms/step - loss: 0.7523 - acc: 0.7362 - val_loss: 0.8416 - val_acc: 0.7099\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 139s 3ms/step - loss: 0.7174 - acc: 0.7494 - val_loss: 0.7697 - val_acc: 0.7365\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 134s 3ms/step - loss: 0.6870 - acc: 0.7605 - val_loss: 0.6523 - val_acc: 0.7735\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 132s 3ms/step - loss: 0.6682 - acc: 0.7648 - val_loss: 0.6301 - val_acc: 0.7776\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 132s 3ms/step - loss: 0.6442 - acc: 0.7759 - val_loss: 0.6916 - val_acc: 0.7585\n",
      "Test loss: 0.6916452174186707\n",
      "Test accuracy: 0.7585\n",
      "--- 1357.0992312431335 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), padding='same',\n",
    "                 input_shape=X_train_orig.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(AveragePooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_orig, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_orig, Y_test))\n",
    "score = model.evaluate(X_test_orig, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "deep-neural-network",
   "graded_item_id": "BFd89",
   "launcher_item_id": "AH2rK"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
