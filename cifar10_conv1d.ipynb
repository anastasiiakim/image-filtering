{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we present an algorithm that maps 2D data to 1D and show that 1D CNNs comparable with 2D CNNs. In particular, we read image pixels with Hilbert and modified Sierpinski space-filling curves, and then apply one-dimensional convolutional neural networks. \n",
    "\n",
    "We know that space-filling curves preserve a maximum of spatial locality information between elements. We believe that using space-filling curve mapping as a preprocessing tool, preserves enough information of neighbouring pixels to be used by 1D CNNs. We evaluated the classification performance of 1D CNNs on Cifar-10 image dataset. This mapping technique can potentially reduce CNN training cost while perform comparably to 2D CNNs in terms of accuracy.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "\n",
    "\n",
    "from space_filling_curves import rix, hilbert_curve, scan_image_with_hilbert, modified_sierpinski_curve, scan_image_with_sierpinski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIFAR-10 dataset consists of 60000 32x32x3 color images in 10 equal classes. There are 50000 training images and 10000 test images. Each class of images corresponds to a physical object such as airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 32, 32, 3)\n",
      "(40000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n",
      "It is a automobile!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=0)\n",
    "num_classes = 10\n",
    "cifar10_classes = {0:'airplane', 1:'automobile', 2:'bird', 3:'cat', 4:'deer', \n",
    "                      5:'dog', 6:'frog', 7:'horse', 8:'ship', 9:'truck'}\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "def draw_cifar_image(i):\n",
    "    img = x_train[i]\n",
    "    label = y_train[i]    \n",
    "    plt.imshow(img)\n",
    "\n",
    "    \n",
    "print(\"It is a \" + str(cifar10_classes[int(y_train[13])]) + \"!\")\n",
    "draw_cifar_image(13)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read the image pixels with Hilbert space-filling curve or modified Sierpinski space-filling curve. The main difference between these two curves is that modified Sierpinski curve is more symmetrical and closed.\n",
    "\n",
    "Here, for example, we read the red matrix of the 4x4x3 image with Hilbert curve in the following order: 35, 19, 22, 13, 4, 0, 8, 3, 7, 1, 3, 10, 53, 16, 25, 6. We read the red matrix of the 4x4x3 image with modified Sierpinski curve in the following order: 35, 19, 22, 25, 6, 53, 16, 10, 3, 1, 7, 8, 0, 4, 3, 13. The code in Python 3 (see space_filling_curves.py) shows how to build the modified Nth order Sierpinski curve and Nth order Hilbert curve.\n",
    "\n",
    "\n",
    "2nd-order Hilbert curve | 2nd-order modified Sierpi≈Ñski curve\n",
    ":-------------------------:|:-------------------------:\n",
    "<img src=\"images/hilbertRGB.png\" style=\"width:400px;height:300px\"/>  |  <img src=\"images/readwithcurve.png\" style=\"width:400px;height:300px\"/>\n",
    "\n",
    "\n",
    "\n",
    "Although it is possible to use lower order of the curves to read images, it is not recommended for small images. Here we preserve every pixel in image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The order of the curve is 5\n",
      "(40000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n",
      "(40000, 10)\n",
      "(10000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "num_px = x_train.shape[1]\n",
    "N = math.log10(num_px) / math.log10(2)\n",
    "N = int(N) # to cover all pixels\n",
    "print(\"The order of the curve is \" + str(N)) \n",
    "#x,y = modified_sierpinski_curve(N)\n",
    "x,y = hilbert_curve(N)\n",
    "\n",
    "# normalize data\n",
    "X_train_orig = x_train/255.\n",
    "X_val_orig = x_val/255.\n",
    "X_test_orig = x_test/255.\n",
    "mtrain = X_train_orig.shape[0]\n",
    "mval = X_val_orig.shape[0]\n",
    "mtest = X_test_orig.shape[0]\n",
    "\n",
    "# convert to one-hot presentation\n",
    "Y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "Y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "Y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# print shapes\n",
    "print(X_train_orig.shape)\n",
    "print(X_val_orig.shape)\n",
    "print(X_test_orig.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_val.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create arrays of zeros and read pixels with Hilbert curve for Red, Green, and Blue channels. The data therefore transformed from (number of examples, number of pixels, number of pixels, 3) to (number of examples, $2^{2N}$, 3), where $N$ is the order of the curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 1024, 3)\n",
      "(10000, 1024, 3)\n",
      "(10000, 1024, 3)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.zeros([X_train_orig.shape[0], 2**(2*N), X_train_orig.shape[3]])\n",
    "val_data = np.zeros([X_test_orig.shape[0], 2**(2*N), X_val_orig.shape[3]])\n",
    "test_data = np.zeros([X_test_orig.shape[0], 2**(2*N), X_test_orig.shape[3]])\n",
    "\n",
    "train_data[:, :, 0] = scan_image_with_hilbert(N, mtrain, X_train_orig[:, :, :, 0], x, y)        \n",
    "val_data[:, :, 0] = scan_image_with_hilbert(N, mval, X_val_orig[:, :, :, 0], x, y) \n",
    "test_data[:, :, 0] = scan_image_with_hilbert(N, mtest, X_test_orig[:, :, :, 0], x, y) \n",
    "\n",
    "train_data[:, :, 1] = scan_image_with_hilbert(N, mtrain, X_train_orig[:, :, :, 1], x, y)  \n",
    "val_data[:, :, 1] = scan_image_with_hilbert(N, mval, X_val_orig[:, :, :, 1], x, y) \n",
    "test_data[:, :, 1] = scan_image_with_hilbert(N, mtest, X_test_orig[:, :, :, 1], x, y) \n",
    "\n",
    "train_data[:, :, 2] = scan_image_with_hilbert(N, mtrain, X_train_orig[:, :, :, 2], x, y)    \n",
    "val_data[:, :, 2] = scan_image_with_hilbert(N, mval, X_val_orig[:, :, :, 2], x, y) \n",
    "test_data[:, :, 2] = scan_image_with_hilbert(N, mtest, X_test_orig[:, :, :, 2], x, y) \n",
    "\n",
    "# new shapes\n",
    "print(train_data.shape)\n",
    "print(val_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the model as a Sequential model in Keras. We define the model as having two blocks of two 1D CNN layers followed by  a pooling layer, then a dropout layer for regularization. After that, the learned features are flattened to a vector and pass through a fully connected layer. Then the output layer used to make predictions. We use batch normalization and ELU activation function elsewhere. Adam optimizer with default learning rate of 0.001 was used. We trained this model for 10 epochs using batches of 16 examples and achieved 92.25% train accuracy, 69.45% validation accuracy, and 68.45% test accuracy. It took 3334 seconds to run. \n",
    "\n",
    "More details about the model hyperparameters are below:\n",
    "\n",
    "In the first block we use\n",
    "- 1D convolutional layers with 64 filters (feature detectors), each of length 4 (kernel size or sliding window). In this initial layer, 64 sliding windows of size 4 will run through the data to learn basic features. This allows us to train 64 different features on the first layer of the network.\n",
    "- The exponential linear unit (ELU) activation function has a nonzero gradient for $z < 0$. It was used to avoid the dying units issue (some neurons die and output 0) when using RELU.\n",
    "- To zero-center and normalize the inputs, we use the batch normalization techique that evaluates mean and standard deviation  of the inputs over the current mini-batch. This technique makes the networks much less sensitive to the weight initialization.\n",
    "- MaxPooling of size 2 and stride 1 was applied by taking the max value of every 2 features. This means that the size of the output matrix of this layer is only a half of the input matrix.\n",
    "- Dropout layer with rate 0.25 was used to ensure that at every trainig step, every input neuron has the probability 0.25 of being temporarily dropped (ignored). This means that the network becomes less sensitive to react to smaller variations in the data, and likely will increase test accuracy.\n",
    "\n",
    "The second block is similar to the first one, except 128 filters were used and AveragePooling was used instead of MaxPooling. After that we 'flatten' and turn the output into a vector. The first fully connected layer defined as Dense(128) takes the input from the features analysis and applies weights to predict the correct label. The last output layer defined by Dense(num_classes) uses a softmax activation function to give probabilities for the num_classes=10 output classes.\n",
    "\n",
    "\n",
    "We train our model for 10 epochs, meaning that we completely pass through the training dataset 10 times. After evey 16 training examples (batch_size=16) the model's internal parameters were updated. One can use larger batch size like 32 or 64 which will lead to faster updates but may take more time to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.2876819651544094\n",
      "Train accuracy: 0.92245\n",
      "Val loss: 0.8860030125617981\n",
      "Val accuracy: 0.6945\n",
      "Test loss: 0.9182343528747559\n",
      "Test accuracy: 0.6845\n",
      "--- 3333.5106382369995 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(64, 4, input_shape=train_data.shape[1:]))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(64, 4))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Conv1D(128, 4))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(128, 4))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(AveragePooling1D(pool_size=2))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "opt = keras.optimizers.Adam() #keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=\"hilbert_weights.hdf5\", verbose=0, monitor='val_loss',save_best_only=True, mode='auto')  \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=[checkpoint],\n",
    "          verbose=0,\n",
    "          validation_data=(val_data, Y_val))\n",
    "\n",
    "model.load_weights('hilbert_weights.hdf5')\n",
    "score_train = model.evaluate(train_data, Y_train, verbose=0)\n",
    "score_val = model.evaluate(val_data, Y_val, verbose=0)\n",
    "score_test = model.evaluate(test_data, Y_test, verbose=0)\n",
    "print('Train loss:', score_train[0])\n",
    "print('Train accuracy:', score_train[1])\n",
    "print('Val loss:', score_val[0])\n",
    "print('Val accuracy:', score_val[1])\n",
    "print('Test loss:', score_test[0])\n",
    "print('Test accuracy:', score_test[1])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously we read pixels with Hilbert curve. Here we read pixels with modified Sierpinski curve and use the same model as above to train 1D CNNs. After 10 epochs the model achieved 91.35% train accuracy, 70.36% test accuracy, and 69.87% validation accuracy in 3334 seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.29816328558325766\n",
      "Train accuracy: 0.913475\n",
      "Val loss: 0.8763399494171142\n",
      "Val accuracy: 0.7036\n",
      "Test loss: 0.8978019725322723\n",
      "Test accuracy: 0.6987\n",
      "--- 3334.4803388118744 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# read with modified Sierpinski curve\n",
    "\n",
    "x,y = modified_sierpinski_curve(N)\n",
    "\n",
    "train_data = np.zeros([X_train_orig.shape[0], 2**(2*N), X_train_orig.shape[3]])\n",
    "val_data = np.zeros([X_test_orig.shape[0], 2**(2*N), X_val_orig.shape[3]])\n",
    "test_data = np.zeros([X_test_orig.shape[0], 2**(2*N), X_test_orig.shape[3]])\n",
    "\n",
    "train_data[:, :, 0] = scan_image_with_sierpinski(N, mtrain, X_train_orig[:, :, :, 0], x, y)        \n",
    "val_data[:, :, 0] = scan_image_with_sierpinski(N, mval, X_val_orig[:, :, :, 0], x, y) \n",
    "test_data[:, :, 0] = scan_image_with_sierpinski(N, mtest, X_test_orig[:, :, :, 0], x, y) \n",
    "\n",
    "train_data[:, :, 1] = scan_image_with_sierpinski(N, mtrain, X_train_orig[:, :, :, 1], x, y)  \n",
    "val_data[:, :, 1] = scan_image_with_sierpinski(N, mval, X_val_orig[:, :, :, 1], x, y) \n",
    "test_data[:, :, 1] = scan_image_with_sierpinski(N, mtest, X_test_orig[:, :, :, 1], x, y) \n",
    "\n",
    "train_data[:, :, 2] = scan_image_with_sierpinski(N, mtrain, X_train_orig[:, :, :, 2], x, y)    \n",
    "val_data[:, :, 2] = scan_image_with_sierpinski(N, mval, X_val_orig[:, :, :, 2], x, y) \n",
    "test_data[:, :, 2] = scan_image_with_sierpinski(N, mtest, X_test_orig[:, :, :, 2], x, y) \n",
    "\n",
    "\n",
    "# train 1D CNNs\n",
    "start_time = time.time()\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(64, 4, input_shape=train_data.shape[1:]))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(64, 4))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Conv1D(128, 4))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(128, 4))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(AveragePooling1D(pool_size=2))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "opt = keras.optimizers.Adam() #keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=\"sierpinski_weights.hdf5\", verbose=0, monitor='val_loss',save_best_only=True, mode='auto')  \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=[checkpoint],\n",
    "          verbose=0,\n",
    "          validation_data=(val_data, Y_val))\n",
    "\n",
    "model.load_weights('sierpinski_weights.hdf5')\n",
    "score_train = model.evaluate(train_data, Y_train, verbose=0)\n",
    "score_val = model.evaluate(val_data, Y_val, verbose=0)\n",
    "score_test = model.evaluate(test_data, Y_test, verbose=0)\n",
    "print('Train loss:', score_train[0])\n",
    "print('Train accuracy:', score_train[1])\n",
    "print('Val loss:', score_val[0])\n",
    "print('Val accuracy:', score_val[1])\n",
    "print('Test loss:', score_test[0])\n",
    "print('Test accuracy:', score_test[1])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we apply various 2D CNNs to the original data. We use similar architecture as for 1D CNNs. The model achieves 89-92% train accuracy, 78-81% validation accuracy, and 78-80% test accuracy in around 2400 seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3256031199216843\n",
      "Train accuracy: 0.8938\n",
      "Val loss: 0.6478643950462342\n",
      "Val accuracy: 0.7829\n",
      "Test loss: 0.6506906617164612\n",
      "Test accuracy: 0.7812\n",
      "--- 2664.7220237255096 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (4,4), input_shape=X_train_orig.shape[1:]))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (4,4)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Conv2D(128, (4,4)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (4,4)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(AveragePooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "opt = keras.optimizers.Adam() #keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=\"cnn2d_weights.hdf5\", verbose=0, monitor='val_loss',save_best_only=True, mode='auto')  \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_orig, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=[checkpoint],\n",
    "          verbose=0,\n",
    "          validation_data=(X_val_orig, Y_val))\n",
    "\n",
    "model.load_weights('cnn2d_weights.hdf5')\n",
    "score_train = model.evaluate(X_train_orig, Y_train, verbose=0)\n",
    "score_val = model.evaluate(X_val_orig, Y_val, verbose=0)\n",
    "score_test = model.evaluate(X_test_orig, Y_test, verbose=0)\n",
    "print('Train loss:', score_train[0])\n",
    "print('Train accuracy:', score_train[1])\n",
    "print('Val loss:', score_val[0])\n",
    "print('Val accuracy:', score_val[1])\n",
    "print('Test loss:', score_test[0])\n",
    "print('Test accuracy:', score_test[1])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.22277186031341553\n",
      "Train accuracy: 0.92985\n",
      "Val loss: 0.5760130873203277\n",
      "Val accuracy: 0.8129\n",
      "Test loss: 0.58989321641922\n",
      "Test accuracy: 0.8029\n",
      "--- 2414.280870437622 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Create the model 2824\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3,3), input_shape=X_train_orig.shape[1:]))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3,3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3,3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(AveragePooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "opt = keras.optimizers.Adam() #keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=\"cnn2d_elu_weights.hdf5\", verbose=0, monitor='val_loss',save_best_only=True, mode='auto')  \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_orig, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=[checkpoint],\n",
    "          verbose=0,\n",
    "          validation_data=(X_val_orig, Y_val))\n",
    "\n",
    "model.load_weights('cnn2d_elu_weights.hdf5')\n",
    "score_train = model.evaluate(X_train_orig, Y_train, verbose=0)\n",
    "score_val = model.evaluate(X_val_orig, Y_val, verbose=0)\n",
    "score_test = model.evaluate(X_test_orig, Y_test, verbose=0)\n",
    "print('Train loss:', score_train[0])\n",
    "print('Train accuracy:', score_train[1])\n",
    "print('Val loss:', score_val[0])\n",
    "print('Val accuracy:', score_val[1])\n",
    "print('Test loss:', score_test[0])\n",
    "print('Test accuracy:', score_test[1])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.2805523369759321\n",
      "Train accuracy: 0.9077\n",
      "Val loss: 0.6048455331325531\n",
      "Val accuracy: 0.7941\n",
      "Test loss: 0.6162231415271759\n",
      "Test accuracy: 0.7904\n",
      "--- 2217.8593513965607 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Create the model 2824\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (2,2), input_shape=X_train_orig.shape[1:]))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (2,2)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Conv2D(128, (2,2)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (2,2)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(AveragePooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "opt = keras.optimizers.Adam() #keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=\"cnn2d_elu_weights.hdf5\", verbose=0, monitor='val_loss',save_best_only=True, mode='auto')  \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_orig, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=[checkpoint],\n",
    "          verbose=0,\n",
    "          validation_data=(X_val_orig, Y_val))\n",
    "\n",
    "model.load_weights('cnn2d_elu_weights.hdf5')\n",
    "score_train = model.evaluate(X_train_orig, Y_train, verbose=0)\n",
    "score_val = model.evaluate(X_val_orig, Y_val, verbose=0)\n",
    "score_test = model.evaluate(X_test_orig, Y_test, verbose=0)\n",
    "print('Train loss:', score_train[0])\n",
    "print('Train accuracy:', score_train[1])\n",
    "print('Val loss:', score_val[0])\n",
    "print('Val accuracy:', score_val[1])\n",
    "print('Test loss:', score_test[0])\n",
    "print('Test accuracy:', score_test[1])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "deep-neural-network",
   "graded_item_id": "BFd89",
   "launcher_item_id": "AH2rK"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
